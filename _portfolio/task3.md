---
caption:
  title: Task 3
  subtitle:  Inference Speed, Model Size and Score Assessment.
  thumbnail: assets/img/portfolio/task3_resized.jpg
  
title: Task 3
subtitle:  Inference Speed, Model Size and Score Assessment.
image: assets/img/portfolio/task3_resized.jpg
alt: Speed, size and score

---
<div style="text-align: justify">The main objective of this task is to evaluate the submitted models on their feasibility and applicability of deploying the methods for real life applications. In order to evaluate the submitted methods under previous tasks (Task T1 and T2), we separate this task into two sub-tasks:<br><br>
<ol style="text-align: left;">
<li>T3.1 - This sub-task takes the score of T1 into consideration, we intend to evaluate the speed, size and text spotting score of the submitted model.</li>
<li>T3.2 - This sub-task is designed to evaluate the submitted model on inference speed, loaded memory size, text spotting and also multi-class classification score as stated in T2.</li>
</ol>
The participants will be required to package and submit their inference code, model and weights in a docker image. We will then use the Docker image to infer on the test set. This is to study the relationship between speed, size, and score, where the end goal is to research and develop a well balanced model based on these three aspects. The submitted model is expected to achieve an optimal result with minimal inference time and occupied GPU memory, a representation of the efficiency and effectiveness of the model.
</div>
___

<ul style="text-align: left;">
<li>Input: Docker image with inference code, model, trained weights.</li>
<li>Output: Inference speed, Model Size and Respective Score.</li>
</ul>

